== A very simple nueral network ==
* https://github.com/dhkim9549/ai-study/blob/main/test/simple-nn.py[simple-nn.py]
* uses only numpy
* predicts xor operations


==== Result ====
----
# python3 simple-nn.py
X = [[1. 1.]
 [1. 1.]
 [0. 0.]
 [0. 0.]
 [1. 1.]
 [1. 1.]
 [0. 0.]
 [1. 0.]
 [0. 0.]
 [1. 0.]
 [0. 1.]
 [1. 1.]
 [1. 1.]
 [0. 1.]
 [1. 0.]
 [1. 1.]
 [1. 1.]
 [1. 0.]
 [1. 0.]
 [1. 1.]]
Y = [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [0.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [1.]
 [0.]
 [0.]
 [1.]
 [1.]
 [0.]]
 
 i = 0
error = [299.11357441]
L2 = [[-4.94559954]
 [-4.94559954]
 [ 0.        ]
 [ 0.        ]
 [-4.94559954]
 [-4.94559954]
 [ 0.        ]
 [-0.37312632]
 [ 0.        ]
 [-0.37312632]
 [-4.89727063]
 [-4.94559954]
 [-4.94559954]
 [-4.89727063]
 [-0.37312632]
 [-4.94559954]
 [-4.94559954]
 [-0.37312632]
 [-0.37312632]
 [-4.94559954]]
 
 ...
 
i = 900
error = [9.45064239e-14]
L2 = [[3.67494533e-08]
 [3.67494533e-08]
 [0.00000000e+00]
 [0.00000000e+00]
 [3.67494533e-08]
 [3.67494533e-08]
 [0.00000000e+00]
 [9.99999942e-01]
 [0.00000000e+00]
 [9.99999942e-01]
 [9.99999819e-01]
 [3.67494533e-08]
 [3.67494533e-08]
 [9.99999819e-01]
 [9.99999942e-01]
 [3.67494533e-08]
 [3.67494533e-08]
 [9.99999942e-01]
 [9.99999942e-01]
 [3.67494533e-08]] 

----

== A very simple nueral network using pytorch backward function ==
* https://github.com/dhkim9549/ai-study/blob/main/test/basic-nn-torch.py[basic-nn-torch.py]
* uses pytorch backward function to compute the gradient of weights
* updates weights manually using the gradients
* predicts xor operations


==== Result ====
----
# python3 basic-nn-torch.py

i = 0
error = tensor([0.8932], dtype=torch.float64, grad_fn=<PowBackward0>)
B = tensor([[ 1.5359],
        [-1.4768],
        [-0.7959],
        [ 0.9203],
        [-0.1051],
        [-0.1967],
        [-0.2857],
        [-0.4806],
        [ 0.9489],
        [-0.8939]], dtype=torch.float64, requires_grad=True)
A = tensor([[ 0.4273,  1.9875, -1.1466, -0.5465, -0.1829, -0.7146,  1.0741, -1.0435,
         -0.7468,  1.1360],
        [ 0.2434, -0.9609, -1.8127,  2.1923, -0.9406, -0.6608, -0.4683, -0.4235,
         -1.3422,  0.5185]], dtype=torch.float64, requires_grad=True)

i = 100
error = tensor([0.0004], dtype=torch.float64, grad_fn=<PowBackward0>)
B = tensor([[ 1.9211],
        [-0.4611],
        [-0.7959],
        [ 0.7235],
        [-0.1051],
        [-0.1967],
        [ 0.3347],
        [-0.4806],
        [ 0.9489],
        [-0.6879]], dtype=torch.float64, requires_grad=True)
A = tensor([[ 1.0182,  1.5776, -1.1466, -0.8516, -0.1829, -0.7146,  1.0414, -1.0435,
         -0.7468,  0.8660],
        [-0.7391, -0.6418, -1.8127,  2.0136, -0.9406, -0.6608, -0.5620, -0.4235,
         -1.3422,  0.6938]], dtype=torch.float64, requires_grad=True)

i = 200
error = tensor([1.2076e-07], dtype=torch.float64, grad_fn=<PowBackward0>)
B = tensor([[ 1.9285],
        [-0.4554],
        [-0.7959],
        [ 0.7335],
        [-0.1051],
        [-0.1967],
        [ 0.3400],
        [-0.4806],
        [ 0.9489],
        [-0.6884]], dtype=torch.float64, requires_grad=True)
A = tensor([[ 1.0167,  1.5780, -1.1466, -0.8596, -0.1829, -0.7146,  1.0412, -1.0435,
         -0.7468,  0.8666],
        [-0.7601, -0.6368, -1.8127,  2.0138, -0.9406, -0.6608, -0.5657, -0.4235,
         -1.3422,  0.6936]], dtype=torch.float64, requires_grad=True)
----

== A very simple nueral network using PyTorch Module ==
* https://github.com/dhkim9549/ai-study/blob/main/test/basic-nn-torch.py[troch-nn.py]
* predicts xor operations


==== Result ====
----

# python3 torch-nn.py
model = NeuralNetwork(
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): ReLU()
    (2): Linear(in_features=20, out_features=1, bias=True)
  )
)
X = [[1. 0.]
 [1. 0.]
 [1. 1.]
 [1. 1.]
 [1. 1.]
 [1. 1.]
 [1. 0.]
 [1. 0.]
 [0. 1.]
 [1. 0.]
 [0. 1.]
 [1. 1.]
 [1. 0.]
 [1. 1.]
 [1. 1.]
 [0. 0.]
 [0. 1.]
 [1. 0.]
 [1. 0.]
 [1. 0.]]
Y = [[1.]
 [1.]
 [0.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [0.]
 [1.]
 [0.]
 [0.]
 [0.]
 [1.]
 [1.]
 [1.]
 [1.]]

i = 0
loss = 0.5730758905410767
y = tensor([[-0.0294],
        [-0.0294],
        [ 0.2492],
        [ 0.2492],
        [ 0.2492],
        [ 0.2492],
        [-0.0294],
        [-0.0294],
        [ 0.2953],
        [-0.0294],
        [ 0.2953],
        [ 0.2492],
        [-0.0294],
        [ 0.2492],
        [ 0.2492],
        [-0.0244],
        [ 0.2953],
        [-0.0294],
        [-0.0294],
        [-0.0294]], grad_fn=<AddmmBackward0>)

i = 100
loss = 0.0027647048700600863
y = tensor([[0.9871],
        [0.9871],
        [0.0068],
        [0.0068],
        [0.0068],
        [0.0068],
        [0.9871],
        [0.9871],
        [0.9591],
        [0.9871],
        [0.9591],
        [0.0068],
        [0.9871],
        [0.0068],
        [0.0068],
        [0.2201],
        [0.9591],
        [0.9871],
        [0.9871],
        [0.9871]], grad_fn=<AddmmBackward0>)

...

i = 900
loss = 9.103828801926284e-14
y = tensor([[1.0000e+00],
        [1.0000e+00],
        [1.3411e-07],
        [1.3411e-07],
        [1.3411e-07],
        [1.3411e-07],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.3411e-07],
        [1.0000e+00],
        [1.3411e-07],
        [1.3411e-07],
        [1.0878e-06],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00]], grad_fn=<AddmmBackward0>)
